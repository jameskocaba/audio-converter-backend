import gevent.monkey
gevent.monkey.patch_all()

import os, uuid, logging, glob, zipfile, certifi, shutil, gc, time
from flask import Flask, request, send_file, jsonify, Response, stream_with_context
from flask_cors import CORS
from yt_dlp import YoutubeDL
import json
from concurrent.futures import ThreadPoolExecutor, as_completed

# SSL & Logging
os.environ['SSL_CERT_FILE'] = certifi.where()
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app, resources={r"/*": {"origins": "*"}})

DOWNLOAD_FOLDER = os.path.join(os.getcwd(), 'downloads')
os.makedirs(DOWNLOAD_FOLDER, exist_ok=True)

MAX_WORKERS = 1 
MAX_SONGS = 500
active_tasks = {}

def cleanup_memory():
    gc.collect()

def process_single_track(url, session_dir, track_index, ffmpeg_exe, session_id):
    """Processes track and returns (success_bool, track_index, actual_title)"""
    try:
        if active_tasks.get(session_id) is True:
            return False, track_index, "Cancelled"

        # Unique temp prefix for this worker to identify its file
        temp_id = str(uuid.uuid4())[:8]
        
        ydl_opts = {
            'format': 'bestaudio/best',
            'writethumbnail': True,
            'postprocessors': [
                {'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3', 'preferredquality': '192'},
                {'key': 'FFmpegThumbnailsConvertor', 'format': 'jpg'},
                {'key': 'EmbedThumbnail'},
                {'key': 'FFmpegMetadata', 'add_metadata': True}
            ],
            # Use temp_id to ensure we find the right file later
            'outtmpl': os.path.join(session_dir, f'{temp_id}_%(title)s.%(ext)s'),
            'playlist_items': str(track_index),
            'ffmpeg_location': ffmpeg_exe,
            'ignoreerrors': True,
            'quiet': True,
            'cachedir': False,
        }
        
        with YoutubeDL(ydl_opts) as ydl:
            result = ydl.extract_info(url, download=True)
            # Fetch title from the actual download result if possible
            actual_title = result.get('title', f"Track {track_index}")
            if 'entries' in result and result['entries']:
                actual_title = result['entries'][0].get('title', actual_title)

        # Locate the specific MP3 generated by this worker
        downloaded_files = glob.glob(os.path.join(session_dir, f"{temp_id}_*.mp3"))
        final_path = None
        if downloaded_files:
            # Rename to remove the temp_id prefix for the ZIP
            old_path = downloaded_files[0]
            clean_name = os.path.basename(old_path).replace(f"{temp_id}_", "")
            final_path = os.path.join(session_dir, clean_name)
            os.rename(old_path, final_path)
            
        return True, track_index, actual_title
        
    except Exception as e:
        logger.error(f"Error processing track {track_index}: {e}")
        return False, track_index, "Unknown Track"

def generate_conversion_stream(url, session_id):
    session_dir = os.path.join(DOWNLOAD_FOLDER, session_id)
    os.makedirs(session_dir, exist_ok=True)
    zip_path = os.path.join(session_dir, "soundcloud_bundle.zip")
    
    ffmpeg_exe = 'ffmpeg' # Adjust path if necessary for Render
    
    try:
        # 1. Initial Metadata Fetch
        yield f"data: {json.dumps({'type': 'status', 'message': 'Fetching playlist info...'})}\n\n"
        
        info_opts = {'extract_flat': True, 'quiet': True, 'cachedir': False}
        with YoutubeDL(info_opts) as ydl:
            info = ydl.extract_info(url, download=False)
            entries = info.get('entries', [info])
            total_tracks = min(len(entries), MAX_SONGS)
        
        yield f"data: {json.dumps({'type': 'total', 'total': total_tracks})}\n\n"

        processed_count = 0
        successful_tracks = []
        
        # 2. Sequential Batches (2 at a time)
        track_indices = list(range(1, total_tracks + 1))
        
        for i in range(0, len(track_indices), MAX_WORKERS):
            if active_tasks.get(session_id) is True: break
            
            batch = track_indices[i : i + MAX_WORKERS]
            with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
                futures = [executor.submit(process_single_track, url, session_dir, idx, ffmpeg_exe, session_id) for idx in batch]
                
                for future in as_completed(futures):
                    success, idx, track_name = future.result()
                    if success:
                        processed_count += 1
                        successful_tracks.append({"name": track_name, "downloadLink": "#"})
                        
                        # 3. Incremental Zipping
                        # Find MP3s (excluding zip) and move them into zip immediately
                        files_to_zip = glob.glob(os.path.join(session_dir, "*.mp3"))
                        if files_to_zip:
                            with zipfile.ZipFile(zip_path, 'a', zipfile.ZIP_DEFLATED) as z:
                                for f in files_to_zip:
                                    z.write(f, os.path.basename(f))
                                    os.remove(f) # Delete MP3 to save RAM/Disk
                        
                        yield f"data: {json.dumps({'type': 'progress', 'current': processed_count, 'total': total_tracks, 'track': track_name})}\n\n"

            cleanup_memory()

        # 4. Finalize
        zip_link = f"/download/{session_id}/soundcloud_bundle.zip"
        yield f"data: {json.dumps({'type': 'done', 'status': 'success', 'tracks': successful_tracks, 'zipLink': zip_link})}\n\n"

    except Exception as e:
        yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"
    finally:
        active_tasks.pop(session_id, None)
        cleanup_memory()

# Flask Routes follow original logic...